# ðŸ”— LinkRay - AI Link Analyzer

**Know before you visit.**

LinkRay is a modern, full-stack web app that uses AI to analyze, summarize, and score the safety of any website link. It features user authentication, smart caching, beautiful UI, and robust error handlingâ€”all built on a 100% free-tier stack.

---

## ðŸš€ Features

- ðŸ¤– **AI-Powered Analysis**: Google Gemini (multi-model fallback) for content and risk scoring
- ðŸ›¡ï¸ **Safety Scoring**: 0-100 risk score with color-coded UI
- ðŸ“¸ **Screenshots**: Website previews via Microlink API
- âš¡ **Smart Caching**: 24-hour cache per user+URL (Supabase)
- ðŸ‘¤ **User Accounts**: Google OAuth login, per-user scan history
- ðŸŽ¨ **Modern UI**: Tailwind CSS, dark mode, skeleton loaders for images
- ðŸ“ **Summaries & Tags**: AI-generated summaries, categories, and tags
- ðŸ†“ **100% Free Stack**: No paid services required

---

## ðŸ› ï¸ Tech Stack

- **Framework**: Next.js 14+ (App Router)
- **Styling**: Tailwind CSS
- **Database**: Supabase (PostgreSQL, RLS, policies)
- **AI**: Google Gemini (Gemma, Flash, fallback logic)
- **Scraping**: Cheerio (static, no headless browser)
- **Screenshots**: Microlink API
- **Language**: TypeScript

---

## ðŸ—ï¸ Project Structure

```
linkray-app/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ analyze/       # Main AI analysis API
â”‚   â”‚   â”‚   â””â”€â”€ route.ts
â”‚   â”‚   â”œâ”€â”€ analyze/deep/  # Deep crawl AI analysis
â”‚   â”‚   â”‚   â””â”€â”€ route.ts
â”‚   â”‚   â””â”€â”€ recent/        # Recent scans API
â”‚   â”‚       â””â”€â”€ route.ts
â”‚   â”œâ”€â”€ globals.css        # Global styles
â”‚   â”œâ”€â”€ layout.tsx         # Root layout
â”‚   â””â”€â”€ page.tsx           # Main UI (search, results)
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ supabase.ts        # Supabase client & helpers
â”‚   â””â”€â”€ utils.ts           # Utility functions (hash, crawl, etc.)
â”œâ”€â”€ types/
â”‚   â””â”€â”€ index.ts           # TypeScript interfaces
â”œâ”€â”€ supabase-schema.sql    # DB schema & RLS policies
â”œâ”€â”€ supabase-migration-*.sql # DB migrations
â”œâ”€â”€ .env.example           # Env vars template
â”œâ”€â”€ package.json           # Dependencies
â”œâ”€â”€ tailwind.config.ts     # Tailwind config
â”œâ”€â”€ next.config.js         # Next.js config
â””â”€â”€ README.md              # This file
```

---

## âš¡ Quick Start

1. **Clone & Install**
   ```bash
   git clone https://github.com/yourname/linkray-app.git
   cd linkray-app
   npm install
   ```
2. **Set Up Supabase**
   - Create a project at [supabase.com](https://supabase.com)
   - Run `supabase-schema.sql` and all `supabase-migration-*.sql` in SQL Editor
   - Get your Project URL and anon key from Settings > API
3. **Get Google Gemini API Key**
   - Go to [Google AI Studio](https://makersuite.google.com/app/apikey)
   - Create and copy your API key
4. **Configure Environment**
   - Copy `.env.example` to `.env` and fill in your keys
5. **Run the App**
   ```bash
   npm run dev
   ```
   Open [http://localhost:3000](http://localhost:3000)

---

## ðŸ”‘ Environment Variables

```
NEXT_PUBLIC_SUPABASE_URL=your-supabase-url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key
GEMINI_API_KEY=your-gemini-api-key
```

---

## ðŸ§  How It Works

1. **User signs in** (Google OAuth via Supabase)
2. **User enters a URL**
3. **Cache check**: If scan exists for user+URL in last 24h, return cached result
4. **Scraping**: Fetches and cleans HTML with Cheerio
5. **AI Analysis**: Sends content to Gemini (multi-model fallback)
6. **Screenshot**: Gets preview from Microlink
7. **Save**: Upserts scan to DB (user_id, url_hash unique)
8. **Result**: Returns summary, risk score, tags, screenshot, etc.

---

## ðŸ—„ï¸ Database Schema (Supabase)

```sql
CREATE TABLE scans (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES auth.users(id),
  url_hash TEXT NOT NULL,
  url TEXT NOT NULL,
  summary TEXT NOT NULL,
  risk_score INTEGER NOT NULL CHECK (risk_score >= 0 AND risk_score <= 100),
  reason TEXT NOT NULL,
  category TEXT NOT NULL,
  tags TEXT[] DEFAULT '{}',
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  CONSTRAINT scans_user_url_unique UNIQUE (user_id, url_hash)
);
```

**RLS Policies:**

- Users can only read/insert their own scans
- Updates/deletes are blocked (immutable cache)

---

## ðŸ“¦ API Endpoints

### `POST /api/analyze`

Analyze a URL (quick scan, per-user cache).

**Request:**

```json
{ "url": "https://example.com" }
```

**Response:**

```json
{
  "success": true,
  "data": {
    "id": "uuid",
    "user_id": "uuid",
    "url": "https://example.com",
    "summary": "...",
    "risk_score": 85,
    "reason": "...",
    "category": "Blog",
    "tags": ["tech", "tutorial"],
    "screenshot_url": "https://api.microlink.io/...",
    "created_at": "...",
    "from_cache": false
  }
}
```

### `POST /api/analyze/deep`

Deep crawl and analyze a site (multiple pages, more detail).

### `GET /api/recent`

Get recent scans for the signed-in user.

---

## ðŸŽ¨ UI/UX Highlights

- Responsive dark mode design
- Color-coded safety scores (green/yellow/red)
- Skeleton loader for screenshots
- Error and loading states
- Recent scans list (per user)

---

## ðŸ”’ Security & Safety

- RLS: Users can only access their own scans
- All input validated and sanitized
- Timeout guards on scraping
- No headless browser (static parsing only)
- API keys and secrets in `.env`

---

## ðŸ“ License

MIT License â€” Free for personal or commercial use.

---

## ðŸ™ Credits

- Google Gemini AI
- Supabase
- Microlink
- Next.js
- Vercel

---

## ðŸ’¡ Future Ideas

- [ ] Batch URL analysis
- [ ] Browser extension
- [ ] PDF report export
- [ ] Webhook notifications
- [ ] API rate limiting

---

**Happy scanning!**
